# Примечание об обозначении О-нотация (Big-O)

Полезно знать, насколько быстр алгоритм и сколько места ему нужно. Это позволяет выбрать правильный алгоритм для работы.

Обозначение Big-O дает приблизительное представление о времени работы алгоритма и объеме памяти, который он использует. Когда кто-то говорит: «Этот алгоритм в худшем случае имеет время выполнения  **O(n^2)** и использует **O(n)** пространства», они имеют в виду, что он довольно медленный, но не требует большого количества дополнительных памяти.

Выяснение Big-O алгоритма обычно выполняется с помощью математического анализа. Мы опускаем здесь математику, но полезно знать, что означают разные значения, поэтому вот удобная таблица. **n** относится к количеству элементов данных, которые вы обрабатываете. Например, при сортировке массива из 100 элементов **n = 100**.

О-нотация | Название | Описание
------| ---- | -----------
**O(1)** | константный | **Это лучший вариант.** Алгоритм всегда занимает одинаковое количество времени, независимо от объема данных. Пример: поиск элемента массива по его индексу.
**O(log n)** | логарифмический | **Отлично.** Подобные алгоритмы уменьшают вдвое объем данных с каждой итерацией. Если у вас есть 100 элементов, для поиска ответа требуется около 7 шагов. Для 1000 элементов требуется 10 шагов. А для 1 000 000 элементов требуется всего 20 шагов. Это очень быстро даже для больших объемов данных. Пример: бинарный поиск.
**O(n)** | линейный | **Хорошая производительность.** Если у вас есть 100 элементов, это выполняет 100 единиц работы. Удвоение количества элементов приводит к тому, что алгоритм занимает ровно вдвое больше времени (200 единиц работы). Пример: последовательный поиск.
**O(n log n)** | "линеарифмический" | **Достойная производительность.** Это немного хуже, чем линейное, но не так уж плохо. Пример: самые быстрые алгоритмы сортировки общего назначения.
**O(n^2)** | квадратичный | **Довольно медленно.** Если у вас есть 100 элементов, это означает 100^2 = 10 000 единиц работы. Удвоение количества элементов делает его в четыре раза медленнее (потому что 2 в квадрате равно 4). Пример: алгоритмы, использующие вложенные циклы, такие как сортировка вставками.
**O(n^3)** | кубический | **Низкая производительность.** Если у вас есть 100 элементов, 100^3 = 1 000 000 единиц работы. Удвоение размера ввода делает его в восемь раз медленнее. Пример: умножение матриц.
**O(2^n)** | экспоненциальный | **Очень низкая производительность.** Вы хотите избежать таких алгоритмов, но иногда у вас нет выбора. Добавление всего одного бита ко входу удваивает время работы. Пример: задача коммивояжера.
**O(n!)** | факториал | **Невыносимо медленно.** На то, чтобы что-то сделать, уходит буквально миллион лет.


Ниже приведены несколько примеров для каждой категории производительности:

**O(1)**

  Самый распространенный пример со сложностью O(1) — доступ к индексу массива.

  ```swift
  let value = array[5]
  ```

  Другой пример O(1) — отправка и извлечение из стека.


**O(log n)**

  ```swift
  var j = 1
  while j < n {
    // постоянное время
    j *= 2
  }
  ```  

  Вместо простого увеличения 'j' увеличивается в 2 раза при каждом запуске.

  Алгоритм бинарного поиска является примером сложности O (log n).


**O(n)**

  ```swift
  for i in stride(from: 0, to: n, by: 1) {
    print(array[i])
  }
  ```

  Обход массива и линейный поиск являются примерами сложности O(n).


**O(n log n)**

  ```swift
  for i in stride(from: 0, to: n, by: 1) {
  var j = 1
    while j < n {
      j *= 2
      // постоянное время
    }
  }
  ```

  ИЛИ

  ```swift
  for i in stride(from: 0, to: n, by: 1) {
    func index(after i: Int) -> Int? { // multiplies `i` by 2 until `i` >= `n`
      return i < n ? i * 2 : nil
    }
    for j in sequence(first: 1, next: index(after:)) {
      // постоянное время
    }
  }
  ```

  Сортировка слиянием и сортировка кучей являются примерами сложности O (n log n).


**O(n^2)**

  ```swift
  for i  in stride(from: 0, to: n, by: 1) {
    for j in stride(from: 1, to: n, by: 1) {
      // do constant time stuff
    }
  }
  ```

  Обход простого двумерного массива и пузырьковая сортировка являются примерами сложности O(n^2).


**O(n^3)**

  ```swift
  for i in stride(from: 0, to: n, by: 1) {
    for j in stride(from: 1, to: n, by: 1) {
      for k in stride(from: 1, to: n, by: 1) {
        // постоянное время
      }
    }
  }
  ```  

**O(2^n)**

  Алгоритмы со временем выполнения O(2^n) часто являются рекурсивными алгоритмами, которые решают задачу размера n путем рекурсивного решения двух меньших задач размера n-1.
  В следующем примере выводятся все ходы, необходимые для решения знаменитой задачи «Ханойские башни» для n дисков.
  
  ```swift
  func solveHanoi(n: Int, from: String, to: String, spare: String) {
    guard n >= 1 else { return }
    if n > 1 {
      solveHanoi(n: n - 1, from: from, to: spare, spare: to)
    } else {
      solveHanoi(n: n - 1, from: spare, to: to, spare: from)
    }
  }
  ```


**O(n!)**

  Самый тривиальный пример функции, которая занимает O(n!) времени, приведен ниже.

  ```swift
  func nFacFunc(n: Int) {
    for i in stride(from: 0, to: n, by: 1) {
      nFactFunc(n - 1)
    }
  }
  ```

Часто вам не нужна математика, чтобы понять, что такое Big-O алгоритма, но вы можете просто использовать свою интуицию. Если ваш код использует один цикл, который просматривает все **n** элементы вашего ввода, алгоритм будет **O(n)**. Если код имеет два вложенных цикла, это **O(n^2)**. Три вложенных цикла дают **O(n^3)** и так далее.

Обратите внимание, что нотация Big-O является оценочной и действительно полезна только для больших значений **n**. Например, время выполнения алгоритма [сортировка вставками](Insertion%20Sort/) в наихудшем случае составляет **O(n^2)**. Теоретически это хуже, чем время выполнения для [сортировки слиянием](Merge%20Sort/), которое составляет **O(n log n)**. Но для небольших объемов данных сортировка вставками выполняется быстрее, особенно если массив уже частично отсортирован!

Если вы находите это запутанным, не позволяйте этому Big-O сильно беспокоить вас. В основном это полезно при сравнении двух алгоритмов, чтобы выяснить, какой из них лучше. Но в итоге все же хочется проверить на практике, какой из них действительно лучший. А если объем данных относительно невелик, то даже медленный алгоритм будет достаточно быстр для
